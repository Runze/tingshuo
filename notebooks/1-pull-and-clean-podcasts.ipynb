{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "import feedparser\n",
    "import time\n",
    "from nltk import sent_tokenize\n",
    "import itertools\n",
    "import string\n",
    "import html_text\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils')\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema for `podcasts` dataframe:\n",
    "\n",
    "| column                      | type   | description                                            |\n",
    "|-----------------------------|--------|--------------------------------------------------------|\n",
    "| podcast_id                  | string | Podcast ID                                             |\n",
    "| im_name_label               | string | Podcast name                                           |\n",
    "| im_artist_label             | string | Author name                                            |\n",
    "| category_attributes_term    | string | Category                                               |\n",
    "| link_attributes_href        | string | iTunes link                                            |\n",
    "| country                     | string | Country code                                           |\n",
    "| country_fullname            | string | Country full name                                      |\n",
    "| feedurl                     | string | Feed URL                                               |\n",
    "| artwork                     | string | Artwork URl                                            |\n",
    "| summary_label               | list   | Summary in the original language, split into sentences |\n",
    "| summary_label_en            | list   | Summary in English, split into sentences               |\n",
    "| summary_label_en_cleaned    | list   | Cleaned English summary                                |\n",
    "| summary_episodes_en_cleaned | list   | Tokenized summary and episodes (using spaCy)           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema for `episodes` dataframe:\n",
    "\n",
    "| column                     | type   | description                                                |\n",
    "|----------------------------|--------|------------------------------------------------------------|\n",
    "| episode_id                 | string | Episode ID (the concatenation of date and link)            |\n",
    "| date                       | string |                                                            |\n",
    "| link                       | string |                                                            |\n",
    "| title                      | list   | Title in the original language, split into sentences       |\n",
    "| title_en                   | list   | Title in English, split into sentences                     |\n",
    "| title_en_cleaned           | list   | Cleaned English title                                      |\n",
    "| summary                    | list   | Summary in the original language, split into sentences     |\n",
    "| summary_en                 | list   | Summary in English, split into sentences                   |\n",
    "| summary_en_cleaned         | list   | Cleaned English summary                                    |\n",
    "| summary_en_cleaned_deduped | list   | Cleaned English summary with duplicated sentences removed |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull top podcasts from iTunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_top_podcasts(country, genre_id, limit=50):\n",
    "    url = 'https://itunes.apple.com/{}/rss/topaudiopodcasts/genre={}/limit={}/explicit=true/json'.format(country, genre_id, limit*2)\n",
    "    podcasts = requests.get(url).json()\n",
    "    \n",
    "    # Read json into a dataframe\n",
    "    podcasts = json_normalize(podcasts['feed']['entry'])\n",
    "    podcasts.columns = [re.sub('[^a-z0-9]', '_', col.lower()) for col in podcasts]\n",
    "    podcasts = podcasts[['id_attributes_im_id', 'im_name_label', 'im_artist_label', 'summary_label', 'category_attributes_term', 'link_attributes_href']]\n",
    "    podcasts = podcasts[podcasts['category_attributes_term'].isin(['Society & Culture', 'Personal Journals'])]\n",
    "    podcasts.rename(columns={'id_attributes_im_id': 'podcast_id'}, inplace=True)\n",
    "    podcasts['country'] = country\n",
    "    podcasts.dropna(inplace=True)\n",
    "    \n",
    "    return podcasts.head(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts = []\n",
    "for country in countries:\n",
    "    for genre_id in genre_ids:\n",
    "        podcasts.append(pull_top_podcasts(country, genre_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts = pd.concat(podcasts)\n",
    "podcasts.reset_index(drop=True, inplace=True)\n",
    "podcasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop podcasts with no summary\n",
    "podcasts = podcasts[podcasts['summary_label'].str.strip().str.len() > 1].copy()\n",
    "podcasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add country full names\n",
    "podcasts['country_fullname'] = podcasts['country'].map(countries)\n",
    "podcasts['country_fullname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up `feedUrl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract `feedUrl`\n",
    "def extract_feedurl(podcast_id):\n",
    "    url = 'https://itunes.apple.com/lookup?id=' + podcast_id\n",
    "    podcast = requests.get(url).json()\n",
    "    try:\n",
    "        feedurl = podcast['results'][0]['feedUrl']\n",
    "        artwork_keys = [key for key in podcast['results'][0] if key.startswith('artworkUrl')]\n",
    "        artwork = podcast['results'][0][artwork_keys[-1]]\n",
    "        return feedurl, artwork\n",
    "    except:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts['feedurl'], podcasts['artwork'] = zip(*podcasts['podcast_id'].apply(extract_feedurl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop podcasts with no `feedUrl`\n",
    "podcasts.dropna(inplace=True)\n",
    "podcasts.reset_index(drop=True, inplace=True)\n",
    "podcasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from podcast ID to `feedUrl` for easy processing later\n",
    "# Note there are duplicate podcasts appearing in multiple countries (which is fine)\n",
    "podcast_id_to_feedurl = dict(zip(podcasts['podcast_id'], podcasts['feedurl']))\n",
    "len(podcast_id_to_feedurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull episodes from feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_feed(url, n_episodes=40):\n",
    "    feed = feedparser.parse(url)\n",
    "    if feed['entries']:\n",
    "        episodes = []\n",
    "\n",
    "        # Define fields to pull\n",
    "        field_sources = {\n",
    "            'date': ['published'],\n",
    "            'title': ['title'],\n",
    "            'summary': ['content', 'summary_detail'],\n",
    "            'link': ['links']\n",
    "        }\n",
    "        for episode in feed['entries']:\n",
    "            fields = {}\n",
    "            for field, sources in field_sources.items():\n",
    "                for source in sources:\n",
    "                    if source in episode and len(episode[source]) > 0:\n",
    "                        if source == 'content':\n",
    "                            fields[field] = episode[source][0]['value']\n",
    "                        elif source == 'summary_detail':\n",
    "                            if field not in fields:\n",
    "                                fields[field] = episode[source]['value']\n",
    "                        elif source == 'links':\n",
    "                            for subsource in episode[source]:\n",
    "                                if 'href' in subsource and 'type' in subsource:\n",
    "                                    if 'audio' in subsource['type']:\n",
    "                                        fields[field] = subsource['href']\n",
    "                        else:\n",
    "                            fields[field] = episode[source]\n",
    "\n",
    "            # Do not add an episode if any of the needed attributes is missing\n",
    "            if len(fields) == len(field_sources):\n",
    "                episodes.append(fields)\n",
    "\n",
    "        if episodes:\n",
    "            # Concatenate into a dataframe\n",
    "            episodes = pd.DataFrame(episodes)\n",
    "\n",
    "            # Format dates\n",
    "            episodes['date'] = pd.to_datetime(episodes['date'], utc=True)\n",
    "\n",
    "            # Sort by date and pick the most recent N episodes\n",
    "            episodes = episodes.sort_values('date', ascending=False).head(n_episodes)\n",
    "            episodes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            return episodes\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_id_to_episodes = {}\n",
    "for podcast_id, feedurl in podcast_id_to_feedurl.items():\n",
    "    episodes = None\n",
    "    n_attempts = 3\n",
    "    while episodes is None and n_attempts > 0:\n",
    "        if n_attempts < 3:\n",
    "            time.sleep(5)\n",
    "        episodes = parse_feed(feedurl)\n",
    "        n_attempts -= 1\n",
    "    if episodes is not None:\n",
    "        podcast_id_to_episodes[podcast_id] = episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(podcast_id_to_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check podcasts that are excluded because of missing fields\n",
    "for podcast_id in podcast_id_to_feedurl:\n",
    "    if podcast_id not in podcast_id_to_episodes:\n",
    "        podcast_name = podcasts[podcasts['podcast_id'] == podcast_id]['im_name_label'].values[0]\n",
    "        print(podcast_id, podcast_name, podcast_id_to_feedurl[podcast_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these podcasts\n",
    "podcasts = podcasts[podcasts['podcast_id'].isin(podcast_id_to_episodes)].copy()\n",
    "podcasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediary data\n",
    "podcast_data = {\n",
    "    'podcasts': podcasts,\n",
    "    'podcast_id_to_episodes': podcast_id_to_episodes\n",
    "}\n",
    "\n",
    "pickle.dump(podcast_data, open('data/podcast_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_data = pickle.load(open('data/podcast_data.pkl', 'rb'))\n",
    "podcasts, podcast_id_to_episodes = podcast_data['podcasts'], podcast_data['podcast_id_to_episodes']\n",
    "podcasts.shape, len(podcast_id_to_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean podcast summaries\n",
    "podcasts['summary_label'] = podcasts['summary_label'].apply(clean_text, normalize_cn_punct=True, normalize_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean podcast episodes\n",
    "for episodes in podcast_id_to_episodes.values():\n",
    "    episodes['title'] = episodes['title'].apply(clean_text, normalize_cn_punct=True, normalize_url=True)\n",
    "    episodes['summary'] = episodes['summary'].apply(clean_text, normalize_cn_punct=True, normalize_url=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment sentences for podcast summaries\n",
    "podcasts['summary_label'] = podcasts['summary_label'].apply(tokenize_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment sentences for episodes\n",
    "for episodes in podcast_id_to_episodes.values():\n",
    "    episodes['title'] = episodes['title'].apply(tokenize_sents)\n",
    "    episodes['summary'] = remove_duplicate_summaries(episodes['summary'].tolist(), episodes['title'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove podcasts with too little description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the average number of characters per episodes\n",
    "def count_characters(episodes):\n",
    "    if len(episodes) > 0:\n",
    "        n_chars_title = episodes['title'].str.join(' ').str.len().sum()\n",
    "        n_chars_summary = episodes['summary'].str.join(' ').str.len().sum()\n",
    "        return (n_chars_title + n_chars_summary) / len(episodes)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars_per_podcast = [count_characters(episodes) for episodes in podcast_id_to_episodes.values()]\n",
    "n_chars_per_podcast = pd.Series(n_chars_per_podcast, index=podcast_id_to_episodes.keys())\n",
    "n_chars_per_podcast.quantile(np.arange(0, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove podcasts with less than a certain number of characters\n",
    "n_chars_cutoff = 100\n",
    "podcast_id_to_keep = n_chars_per_podcast[n_chars_per_podcast >= n_chars_cutoff].index\n",
    "len(podcast_id_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts = podcasts[podcasts['podcast_id'].isin(podcast_id_to_keep)].copy()\n",
    "podcasts.reset_index(drop=True, inplace=True)\n",
    "podcasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts['country_fullname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_id_to_episodes = {podcast_id: podcast_id_to_episodes[podcast_id] for podcast_id in podcast_id_to_episodes if podcast_id in podcast_id_to_keep}\n",
    "len(podcast_id_to_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `episode_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episodes in podcast_id_to_episodes.values():\n",
    "    episodes['episode_id'] = episodes['date'].dt.date.astype(str) + '-' + episodes['title'].str.join('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/podcast_data_proc.pkl data/podcast_data_proc-OLD.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "podcast_data = {\n",
    "    'podcasts': podcasts,\n",
    "    'podcast_id_to_episodes': podcast_id_to_episodes\n",
    "}\n",
    "\n",
    "pickle.dump(podcast_data, open('data/podcast_data_proc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
